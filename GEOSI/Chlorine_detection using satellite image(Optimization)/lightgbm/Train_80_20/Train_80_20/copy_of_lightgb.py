# -*- coding: utf-8 -*-
"""Copy of lightGB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ygJRd-XxmEvv0Qo9GqoGqPiPFMNA1nL2
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

input_data = pd.read_excel('Input_X.xlsx')
output_data = pd.read_excel('Output_Y.xlsx')

input_data.head()

output_data.head()

# Checking for missing values in input and output data
print("Missing values in input data:")
print(input_data.isnull().sum())

print("\nMissing values in output data:")
print(output_data.isnull().sum())

# Replace zeros with NaN to treat them as missing values
input_data.replace(0, np.nan, inplace=True)

# Drop rows with any NaN values (this will drop rows with original NaNs or replaced zeros)
input_data.dropna(inplace=True)

# Reset the index after dropping rows
input_data.reset_index(drop=True, inplace=True)

X = input_data
y = output_data['CHL_a']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Feature Scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# LightGBM Regressor
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import numpy as np

# Train LightGBM model
lgb_model = lgb.LGBMRegressor()
lgb_model.fit(X_train, y_train)

# Predict
y_train_pred = lgb_model.predict(X_train)
y_test_pred = lgb_model.predict(X_test)

# Plotting
fig, axs = plt.subplots(1, 2, figsize=(16, 7))

# Training scatter plot
axs[0].scatter(y_train, y_train_pred, alpha=0.5, color="blue")
axs[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--')
axs[0].set_xscale('log')
axs[0].set_yscale('log')
axs[0].set_xlim(10**-2, y_train.max())
axs[0].set_ylim(10**-2, y_train.max())
axs[0].set_xlabel("True Values (Train)")
axs[0].set_ylabel("Predicted Values (Train)")
axs[0].set_title("LightGBM Regression - Training: True vs Predicted")
axs[0].set_aspect('equal', adjustable='box')

# Testing scatter plot
axs[1].scatter(y_test, y_test_pred, alpha=0.5, color="orange")
axs[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[1].set_xscale('log')
axs[1].set_yscale('log')
axs[1].set_xlim(10**-2, y_test.max())
axs[1].set_ylim(10**-2, y_test.max())
axs[1].set_xlabel("True Values (Test)")
axs[1].set_ylabel("Predicted Values (Test)")
axs[1].set_title("LightGBM Regression - Testing: True vs Predicted")
axs[1].set_aspect('equal', adjustable='box')

plt.tight_layout()
plt.show()